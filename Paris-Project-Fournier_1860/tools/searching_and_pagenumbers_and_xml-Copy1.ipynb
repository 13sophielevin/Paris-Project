{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm testing with a corpus . . . \n",
    "\n",
    " . . . with one file.  I test all of this less the line number logic using another, larger corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "paths_to_files = glob.glob('/home/spenteco/Downloads/test_corpus/*.txt')\n",
    "\n",
    "print(len(paths_to_files))\n",
    "\n",
    "# I don't know whether these are place names or not.  Let's pretend they are.\n",
    "terms_to_find = [r'du\\s*Dépôt\\s*de\\s*mendicité\\s*de\\s*Saint-Denis', 'Saint-Gervais']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A routine for writing XML\n",
    "\n",
    "We call this from below . . . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "def write_results_to_xml(file_name, results):\n",
    "\n",
    "    xml_root = etree.Element('matches_and_snippets')\n",
    "    \n",
    "    for r in results:\n",
    "        \n",
    "        match_node = etree.Element('match')\n",
    "        xml_root.append(match_node)\n",
    "        \n",
    "        file_name_node = etree.Element('file_name')\n",
    "        file_name_node.text = r['file_name']\n",
    "        match_node.append(file_name_node)\n",
    "        \n",
    "        pdf_page_number_node = etree.Element('pdf_page_number')\n",
    "        pdf_page_number_node.text = str(r['pdf_page_number'])\n",
    "        match_node.append(pdf_page_number_node)\n",
    "        match_node.append(file_name_node)\n",
    "        \n",
    "        book_page_number_node = etree.Element('book_page_number')\n",
    "        book_page_number_node.text = ''\n",
    "        match_node.append(book_page_number_node)\n",
    "        \n",
    "        matching_term_node = etree.Element('matching_term')\n",
    "        matching_term_node.text = r['matching_term']\n",
    "        match_node.append(matching_term_node)\n",
    "        \n",
    "        snippet_node = etree.Element('snippet')\n",
    "        snippet_node.text = r['snippet']\n",
    "        match_node.append(snippet_node)\n",
    "        \n",
    "    xml_root.getroottree().write(file_name.replace('.txt', '.xml'), encoding='utf-8', pretty_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using (very straight-forward) regular expressions\n",
    "\n",
    "The regular expression can be just a string, like \"Saint-Gervais\".\n",
    "\n",
    "Something like \n",
    "\n",
    "> r'du\\s*Dépôt\\s*de\\s*mendicité\\s*de\\s*Saint-Denis' \n",
    "    \n",
    "lets us search across line breaks, even when the OCR has inserted extra line breaks.  Note that the leading r matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "N_CHARACTERS_BEFORE_MATCH = 1000\n",
    "N_CHARACTERS_AFTER_MATCH = 2000\n",
    "\n",
    "for path_to_file in paths_to_files:\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # Get the file name less the path; we use the full path to read, and this file name in the printed output\n",
    "    file_name = path_to_file.split('/')[-1]\n",
    "    \n",
    "    text = open(path_to_file).read()\n",
    "    \n",
    "    # Where are the form-feed characters in the document?\n",
    "    \n",
    "    page_break_locations = []\n",
    "    \n",
    "    for match in re.finditer('\\x0c', text):\n",
    "        page_break_locations.append(match.start())\n",
    "    \n",
    "    # The actual term matching\n",
    "    \n",
    "    for term in terms_to_find:\n",
    "        \n",
    "        for match in re.finditer(term, text):\n",
    "            \n",
    "            pdf_page_number = 1\n",
    "            for location in page_break_locations:\n",
    "                if location > match.start():\n",
    "                    break\n",
    "                pdf_page_number += 1\n",
    "            \n",
    "            snippet_starting_position = match.start() - N_CHARACTERS_BEFORE_MATCH\n",
    "            if snippet_starting_position < 0:\n",
    "                snippet_starting_position = 0\n",
    "                \n",
    "            snippet_ending_position = match.end() + N_CHARACTERS_AFTER_MATCH\n",
    "            if snippet_ending_position > len(text):\n",
    "                snippet_ending_position = len(text)\n",
    "                \n",
    "            snippet = text[snippet_starting_position: snippet_ending_position]\n",
    "            \n",
    "            results.append({'file_name': file_name, \n",
    "                            'pdf_page_number': pdf_page_number,\n",
    "                            'matching_term': text[match.start(): match.end()], \n",
    "                            'snippet': snippet.replace('\\x0c', '')})\n",
    "            \n",
    "    if len(results) > 0:\n",
    "        \n",
    "        write_results_to_xml(file_name, results)\n",
    "        \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
